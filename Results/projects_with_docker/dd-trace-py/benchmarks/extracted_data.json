{
    "source_code_info": {
        "language": "Python",
        "framework": "Django",
        "dependencies": {
            "pyproject.toml": "[build-system]\nrequires = [\"setuptools_scm[toml]>=4\", \"cython\", \"cmake>=3.24.2,<3.28; python_version>='3.8'\", \"setuptools-rust<2\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"ddtrace\"\ndynamic = [\"version\"]\ndescription = \"Datadog APM client library\"\nreadme = \"README.md\"\nlicense = { text = \"LICENSE.BSD3\" }\nrequires-python = \">=3.8\"\nauthors = [\n    { name = \"Datadog, Inc.\", email = \"dev@datadoghq.com\" },\n]\nclassifiers = [\n    \"Development Status :: 5 - Production/Stable\",\n    \"Programming Language :: Python :: Implementation :: CPython\",\n    \"Programming Language :: Python\",\n    \"Programming Language :: Python :: 3 :: Only\",\n    \"Programming Language :: Python :: 3.8\",\n    \"Programming Language :: Python :: 3.9\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n    \"Programming Language :: Python :: 3.13\",\n]\ndependencies = [\n    \"bytecode>=0.16.0; python_version>='3.13.0'\",\n    \"bytecode>=0.15.1; python_version~='3.12.0'\",\n    \"bytecode>=0.14.0; python_version~='3.11.0'\",\n    \"bytecode>=0.13.0; python_version<'3.11'\",\n    \"envier~=0.6.1\",\n    \"importlib_metadata<=6.5.0; python_version<'3.8'\",\n    \"legacy-cgi>=2.0.0; python_version>='3.13.0'\",\n    \"opentelemetry-api>=1\",\n    \"protobuf>=3\",\n    \"typing_extensions\",\n    \"xmltodict>=0.12\",\n    \"wrapt>=1\",\n]\n\n[project.optional-dependencies]\nopentracing = [\n    \"opentracing>=2.0.0\",\n]\nopenai = [\n    \"tiktoken\",\n]\n\n[project.scripts]\nddtrace-run = \"ddtrace.commands.ddtrace_run:main\"\n\n[project.entry-points.opentelemetry_context]\nddcontextvars_context = \"ddtrace.internal.opentelemetry.context:DDRuntimeContext\"\n\n[project.entry-points.pytest11]\nddtrace = \"ddtrace.contrib.internal.pytest.plugin\"\n\"ddtrace.pytest_bdd\" = \"ddtrace.contrib.internal.pytest_bdd.plugin\"\n\"ddtrace.pytest_benchmark\" = \"ddtrace.contrib.internal.pytest_benchmark.plugin\"\n\n[project.entry-points.'ddtrace.products']\n\"code-origin-for-spans\" = \"ddtrace.debugging._products.code_origin.span\"\n\"dynamic-instrumentation\" = \"ddtrace.debugging._products.dynamic_instrumentation\"\n\"exception-replay\" = \"ddtrace.debugging._products.exception_replay\"\n\"live-debugger\" = \"ddtrace.debugging._products.live_debugger\"\n\"remote-configuration\" = \"ddtrace.internal.remoteconfig.product\"\n\"symbol-database\" = \"ddtrace.internal.symbol_db.product\"\n\"appsec\" = \"ddtrace.internal.appsec.product\"\n\"iast\" = \"ddtrace.internal.iast.product\"\n\n[project.urls]\n\"Bug Tracker\" = \"https://github.com/DataDog/dd-trace-py/issues\"\nChangelog = \"https://github.com/DataDog/dd-trace-py/releases\"\nDocumentation = \"https://ddtrace.readthedocs.io/en/stable/\"\nHomepage = \"https://github.com/DataDog/dd-trace-py\"\n\"Source Code\" = \"https://github.com/DataDog/dd-trace-py/\"\n\n[tool.setuptools_scm]\nversion_scheme = \"release-branch-semver\"  # Must be \"release-branch-semver\" for now in main, see https://github.com/DataDog/dd-trace-py/issues/8801\nwrite_to = \"ddtrace/_version.py\"\n\n[tool.cython-lint]\nmax-line-length = 120\nexclude = '''\n(\n  .venv*\n  | \\.riot\n  | ddtrace/profiling/\n  | test_ci_visibility_api_client_skippable_real_world_responses\\.py\n)\n'''\n\n[tool.black]\nline-length = 120\ntarget_version = ['py37', 'py38', 'py39', 'py310', 'py311', 'py312']\ninclude = '''\\.py[ix]?$'''\nexclude = '''\n(\n  .venv*\n  | \\.riot/\n  | ddtrace/appsec/_ddwaf.pyx$\n  | ddtrace/internal/_encoding.pyx$\n  | ddtrace/internal/_rand.pyx$\n  | ddtrace/internal/_tagset.pyx$\n  | ddtrace/profiling/collector/_traceback.pyx$\n  | ddtrace/profiling/collector/_task.pyx$\n  | ddtrace/profiling/_threading.pyx$\n  | ddtrace/profiling/collector/stack.pyx$\n  | ddtrace/profiling/exporter/pprof_.*_pb2.py$\n  | ddtrace/profiling/exporter/pprof.pyx$\n  | ddtrace/internal/datadog/profiling/crashtracker/_crashtracker.pyx$\n  | ddtrace/internal/datadog/profiling/ddup/_ddup.pyx$\n  | ddtrace/vendor/\n  | ddtrace/appsec/_iast/_taint_tracking/_vendor/\n  | ddtrace/appsec/_iast/_taint_tracking/cmake-build-debug/\n  | ddtrace/_version.py\n  | \\.eggs\n  | \\.git\n  | \\.hg\n  | \\.mypy_cache\n  | \\.nox\n  | \\.tox\n  | \\.venv\n  | _build/\n  | buck-out/\n  | build/\n  | dist/\n  | tests/lib-injection/dd-lib-python-init-test-protobuf-old/addressbook_pb2.py$\n)\n'''\n\n[tool.pyright]\nexclude = [\n  \"**/__pycache__\",\n  \".git\",\n  \".ddriot\",\n  \".ddtox\",\n  \".riot\",\n  \".tox\",\n  \".venv\",\n]\n\n[tool.slotscheck]\nexclude-modules = '''\n(\n  ^ddtrace.(contrib|vendor)\n  | ^tests.(contrib|vendor)\n  # avoid sitecustomize modules as they start services\n  | ddtrace.bootstrap.sitecustomize\n  | ddtrace.profiling.bootstrap.sitecustomize\n  | ddtrace.profiling.auto\n  # also ignore preload module to avoid exception after moving ddtrace.tracing module\n  | ddtrace.bootstrap.preload\n  # protobuf file fails to import\n  | ddtrace.profiling.exporter.pprof_3_pb2\n  | ddtrace.profiling.exporter.pprof_312_pb2\n  | ddtrace.profiling.exporter.pprof_319_pb2\n  | ddtrace.profiling.exporter.pprof_421_pb2\n  # TODO: resolve slot inheritance issues with profiling\n  | ddtrace.profiling.collector\n  | ddtrace,appsec,iast,_taint_tracking.vendor\n  | ddtrace.appsec._ddwaf.ddwaf_types\n  | ddtrace.appsec._iast._taint_tracking\n  | ddtrace.appsec._iast._ast.aspects\n  | ddtrace.appsec._iast._taint_utils\n  | ddtrace.appsec._iast.taint_sinks.sql_injection\n  # DSM specific contribs\n  | ddtrace.internal.datastreams.kafka\n  # libdd_wrapper is a common native dependency, not a module\n  | ddtrace.internal.datadog.profiling.libdd_wrapper\n  # _ddup and _stack_v2 miss a runtime dependency in slotscheck, but ddup and stack_v2 are fine\n  | ddtrace.internal.datadog.profiling.ddup._ddup\n  | ddtrace.internal.datadog.profiling.stack_v2._stack_v2\n  # coverage has version-specific checks that prevent import\n  | ddtrace.internal.coverage.instrumentation_py3_8\n  | ddtrace.internal.coverage.instrumentation_py3_10\n  | ddtrace.internal.coverage.instrumentation_py3_11\n  | ddtrace.internal.coverage.instrumentation_py3_12\n  | ddtrace.internal.coverage.instrumentation_py3_13\n)\n'''\n\n[tool.bandit]\ntargets = [\"ddtrace/\"]\n\n# TODO: Remove excludes\nexclude_dirs = [\n  \"ddtrace/vendor/\",\n  \"ddtrace/appsec/_iast/_taint_tracking/_vendor/\",\n  \"ddtrace/commands/ddtrace_run.py\",\n  \"ddtrace/ext/git.py\",\n  \"ddtrace/ext/test.py\",\n  \"ddtrace/internal/datadog/profiling/ddup/test/interface.py\",\n  \"ddtrace/internal/module.py\",\n  \"ddtrace/internal/processor/stats.py\",\n  \"ddtrace/internal/rate_limiter.py\",\n  \"ddtrace/internal/serverless/mini_agent.py\",\n  \"ddtrace/internal/uwsgi.py\",\n  \"ddtrace/sourcecode/_utils.py\",\n]\n\n[tool.ruff]\nexclude = [\n    \".riot\",\n    \".ddriot\",\n    \".venv*\",\n    \".git\",\n    \"__pycache__\",\n    \".eggs\",\n    \"*.egg\",\n    \"build\",\n    \"ddtrace/__init__.py\",\n    \"ddtrace/vendor/*\",\n    \"ddtrace/appsec/_iast/_taint_tracking/_vendor/*\",\n    \"ddtrace/profiling/exporter/pprof_*pb2.py\",\n    \"tests/profiling/simple_program_gevent.py\",\n    \"tests/contrib/grpc/hello_pb2.py\",\n    \"tests/contrib/django_celery/app/*\",\n    \"tests/contrib/protobuf/schemas/**/*.py\",\n    \"tests/appsec/iast/fixtures/ast/str/non_utf8_content.py\",\n    \"tests/appsec/iast/fixtures/aspects/str/non_utf8_content.py\",\n    \"tests/lib-injection/dd-lib-python-init-test-protobuf-old/addressbook_pb2.py\"\n]\nignore = [\n    \"A003\",\n    \"D100\",\n    \"D101\",\n    \"D102\",\n    \"D103\",\n    \"D104\",\n    \"D105\",\n    \"D106\",\n    \"D107\",\n    \"D200\",\n    \"D202\",\n    \"D204\",\n    \"D205\",\n    \"D208\",\n    \"D210\",\n    \"D300\",\n    \"D400\",\n    \"D401\",\n    \"D403\",\n    \"D404\",\n    \"D413\",\n    \"E203\",\n    \"E231\",\n    \"E721\",\n    \"G201\",\n]\nline-length = 120\nselect = [\n    \"A\",\n    \"D\",\n    \"E\",\n    \"F\",\n    \"G\",\n    \"I\",\n    \"W\",\n]\n\n[tool.ruff.pydocstyle]\nconvention = \"pep257\"\n\n[tool.ruff.isort]\nforce-single-line = true\nlines-after-imports = 2\nforce-sort-within-sections = true\nknown-first-party = [ \"ddtrace\" ]\nrelative-imports-order = \"furthest-to-closest\"\n\n[tool.ruff.per-file-ignores]\n# Exclude typing stubs as vertical line spacing incompatibility with black\n# See: https://github.com/astral-sh/ruff/pull/6501\n\"*.pyi\" = [\"I001\"]\n\n[tool.ruff.lint]\n# Do not auto-fix unused imports (as this deletes things like import ddtrace)\nunfixable = [\"F401\"]\n"
        },
        "database": null,
        "build_system": "poetry",
        "config_files": {
            "docker-compose.yml": "version: \"3\"\n# remember to use this compose file __ONLY__ for development/testing purposes\n\nservices:\n    elasticsearch:\n        image: elasticsearch:7.17.13\n        environment:\n            - discovery.type=single-node\n            - xpack.security.enabled=false\n        ports:\n            - \"127.0.0.1:9200:9200\"\n    opensearch:\n        image: opensearchproject/opensearch:1.3.6\n        environment:\n            - \"DISABLE_SECURITY_PLUGIN=true\"\n            - \"discovery.type=single-node\"\n        ports:\n            - \"127.0.0.1:9201:9200\"\n    cassandra:\n        image: cassandra:3.11.7\n        environment:\n            - MAX_HEAP_SIZE=512M\n            - HEAP_NEWSIZE=256M\n        ports:\n            - \"127.0.0.1:9042:9042\"\n    consul:\n        image: consul:1.6.0\n        ports:\n            - \"127.0.0.1:8500:8500\"\n    postgres:\n        image: postgres:12-alpine\n        environment:\n            - POSTGRES_PASSWORD=postgres\n            - POSTGRES_USER=postgres\n            - POSTGRES_DB=postgres\n        ports:\n            - \"127.0.0.1:5432:5432\"\n    mariadb:\n        image: mariadb:lts\n        environment:\n            - MYSQL_ROOT_PASSWORD=example\n            - MYSQL_DATABASE=test\n            - MYSQL_USER=test\n            - MYSQL_PASSWORD=test\n        ports:\n            - \"127.0.0.1:3306:3306\"\n    mysql:\n        image: mysql:5.7\n        platform: linux/amd64\n        environment:\n            - MYSQL_ROOT_PASSWORD=admin\n            - MYSQL_PASSWORD=test\n            - MYSQL_USER=test\n            - MYSQL_DATABASE=test\n        ports:\n            - \"127.0.0.1:3306:3306\"\n    redis:\n        image: redis:4.0-alpine\n        ports:\n            - \"127.0.0.1:6379:6379\"\n    kafka:\n        platform: linux/arm64\n        image: apache/kafka:3.8.0\n        ports:\n            - \"127.0.0.1:29092:29092\"\n        environment:\n            - ALLOW_PLAINTEXT_LISTENER=yes\n            - KAFKA_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:29092\n            - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://localhost:29092\n            - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT\n            - KAFKA_NODE_ID=1\n            - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT\n            - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1\n            - CLUSTER_ID=5L6g3nShT-eMCtK--X86sw\n            - KAFKA_PROCESS_ROLES=broker,controller\n            - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093\n            - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER\n    rediscluster:\n        platform: linux/amd64\n        image: grokzen/redis-cluster:6.2.0\n        environment:\n            - IP=0.0.0.0\n        ports:\n            - \"127.0.0.1:7000:7000\"\n            - \"127.0.0.1:7001:7001\"\n            - \"127.0.0.1:7002:7002\"\n            - \"127.0.0.1:7003:7003\"\n            - \"127.0.0.1:7004:7004\"\n            - \"127.0.0.1:7005:7005\"\n    mongo:\n        image: mongo:3.6\n        ports:\n            - \"127.0.0.1:27017:27017\"\n    memcached:\n        image: memcached:1.5-alpine\n        ports:\n            - \"127.0.0.1:11211:11211\"\n    moto:\n        image: motoserver/moto:5.1.0\n        environment:\n            - MOTO_PORT=3000\n        ports:\n            - \"127.0.0.1:3000:3000\"\n    rabbitmq:\n        image: rabbitmq:3.7-alpine\n        ports:\n            - \"127.0.0.1:5672:5672\"\n    ddagent:\n        image: datadog/agent:latest\n        environment:\n            - DD_HOSTNAME=github-actions-worker\n            - DD_BIND_HOST=0.0.0.0\n            - DD_REMOTE_CONFIGURATION_ENABLED=true\n            - DD_SITE=${DD_SITE-datadoghq.com}\n            - DD_API_KEY=${DD_API_KEY-invalid_but_this_is_fine}\n            - DD_REMOTE_CONFIGURATION_KEY=${DD_REMOTE_CONFIGURATION_KEY-invalid_but_this_is_fine}\n            - DD_REMOTE_CONFIGURATION_REFRESH_INTERVAL=5s\n            - DD_APM_RECEIVER_SOCKET=/tmp/ddagent/trace.sock\n            - DD_DOGSTATSD_NON_LOCAL_TRAFFIC=true\n        ports:\n            - 8126:8126\n            - 8125:8125/udp\n        volumes:\n          - ddagent:/tmp/ddagent:rw\n    testagent:\n        image: ghcr.io/datadog/dd-apm-test-agent/ddapm-test-agent:v1.20.0\n        ports:\n            - \"127.0.0.1:9126:8126\"\n        volumes:\n            - ./tests/snapshots:/snapshots\n        environment:\n            - LOG_LEVEL=WARNING\n            - SNAPSHOT_DIR=/snapshots\n            - SNAPSHOT_CI=0\n            - DD_POOL_TRACE_CHECK_FAILURES=true\n            - DD_DISABLE_ERROR_RESPONSES=true\n            - ENABLED_CHECKS=trace_content_length,trace_stall,meta_tracer_version_header,trace_count_header,trace_peer_service,trace_dd_service\n            - SNAPSHOT_IGNORED_ATTRS=span_id,trace_id,parent_id,duration,start,metrics.system.pid,metrics.system.process_id,metrics.process_id,meta.runtime-id,meta._dd.p.tid,meta.pathway.hash,metrics._dd.tracer_kr,meta._dd.parent_id,meta.kafka.cluster_id\n\n    vertica:\n        image: vertica/vertica-ce\n        environment:\n          - VP_TEST_USER=dbadmin\n          - VP_TEST_PASSWORD=abc123\n          - VP_TEST_DATABASE=docker\n        ports:\n          - \"127.0.0.1:5433:5433\"\n\n    testrunner:\n        # DEV uncomment to test local changes to the Dockerfile\n        # build:\n        #  context: ./docker\n        #  dockerfile: Dockerfile\n        image: ghcr.io/datadog/dd-trace-py/testrunner:47c7b5287da25643e46652e6d222a40a52f2382a@sha256:3a02dafeff9cd72966978816d1b39b54f5517af4049396923b95c8452f604269\n        command: bash\n        environment:\n            - TOX_SKIP_DIST=True\n        network_mode: host\n        userns_mode: host\n        working_dir: /root/project/\n        volumes:\n          - ddagent:/tmp/ddagent\n          - ./:/root/project\n          - ./.ddtox:/root/project/.tox\n          - ./.riot:/root/project/.riot\n\n    localstack:\n        image: localstack/localstack:1.4.0\n        ports:\n          - \"127.0.0.1:4566:4566\"\n          - \"127.0.0.1:4571:4571\"\n        environment:\n          - SERVICES=${SERVICES- }\n          - DEBUG=${DEBUG- }\n          - LAMBDA_EXECUTOR=local\n          - KINESIS_ERROR_PROBABILITY=${KINESIS_ERROR_PROBABILITY- }\n          - DOCKER_HOST=unix:///var/run/docker.sock\n        volumes:\n          - \"${TMPDIR:-/var/lib/localstack}:/var/lib/localstack\"\n          - \"/var/run/docker.sock:/var/run/docker.sock\"\n\n    httpbin-local:\n      image: kennethreitz/httpbin@sha256:2c7abc4803080c22928265744410173b6fea3b898872c01c5fd0f0f9df4a59fb\n      platform: linux/amd64\n      ports:\n        - \"127.0.0.1:8001:80\"\n\n    pygoat:\n        build:\n            context: .\n            dockerfile: tests/appsec/integrations/pygoat_tests/Dockerfile.pygoat.2.0.1\n        ports:\n            - \"127.0.0.1:8321:8321\"\n        environment:\n            - DD_IAST_ENABLED=true\n            - _DD_IAST_DEBUG=true\n            - DD_IAST_REQUEST_SAMPLING=100\n            - DD_IAST_VULNERABILITIES_PER_REQUEST=100\n            - DD_REMOTE_CONFIGURATION_ENABLED=true\n            - DD_AGENT_PORT=8126\n            - DD_TRACE_AGENT_URL=http://testagent:8126\n            - DD_IAST_DEDUPLICATION_ENABLED=false\n\n    valkey:\n        image: valkey/valkey:8.0-alpine\n        ports:\n            - \"127.0.0.1:6379:6379\"\n\n    valkeycluster:\n        platform: linux/amd64\n        image: grokzen/redis-cluster:6.2.0\n        environment:\n            - IP=0.0.0.0\n        ports:\n            - \"127.0.0.1:7000:7000\"\n            - \"127.0.0.1:7001:7001\"\n            - \"127.0.0.1:7002:7002\"\n            - \"127.0.0.1:7003:7003\"\n            - \"127.0.0.1:7004:7004\"\n            - \"127.0.0.1:7005:7005\"\n\nvolumes:\n    ddagent:\n",
            "benchmarks/Dockerfile": "FROM debian:buster-slim as base\n\nARG PYTHON_VERSION=3.9.15\nARG PYENV_VERSION=2.4.1\nRUN apt-get update && apt-get install --no-install-recommends -y \\\n    make build-essential libssl-dev zlib1g-dev \\\n    libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm \\\n    libncursesw5-dev xz-utils tk-dev libxml2-dev libxmlsec1-dev libffi-dev liblzma-dev \\\n    git ca-certificates\nENV PYENV_ROOT \"/pyenv\"\nWORKDIR \"$PYENV_ROOT\"\nENV PATH \"$PYENV_ROOT/shims:$PYENV_ROOT/bin:$PATH\"\nRUN git clone --depth 1 https://github.com/pyenv/pyenv.git --branch \"v$PYENV_VERSION\" --single-branch \"$PYENV_ROOT\"\nRUN pyenv install \"$PYTHON_VERSION\"\n\nFROM debian:buster-slim\nARG PYTHON_VERSION=3.9.15\n\nCOPY --from=base /pyenv /pyenv\nENV PYENV_ROOT \"/pyenv\"\nENV PATH \"$PYENV_ROOT/shims:$PYENV_ROOT/bin:/root/.cargo/bin/:$PATH\"\nRUN pyenv global \"$PYTHON_VERSION\"\nRUN pip install -U pip\n\nARG SCENARIO=base\n\nENV PYTHONUNBUFFERED 1\nENV PYTHONDONTWRITEBYTECODE 1\n\nWORKDIR /app\n\n# Install required system dependencies\nRUN apt-get update && apt-get install --no-install-recommends -y \\\n  curl \\\n  git \\\n  ca-certificates \\\n  # ddtrace includes c extensions\n  build-essential \\\n  # uuid is used to generate identifier for run if one is not provided\n  uuid-runtime \\\n  # provides ab for testing\n  apache2-utils \\\n  # provides sqlite3 for sql injection tests\n  sqlite3 \\\n  # cleaning up unused files\n  && apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=false \\\n  && rm -rf /var/lib/apt/lists/*\n\n# Install Rust toolchain\nRUN curl https://sh.rustup.rs -sSf | \\\n    sh -s -- --default-toolchain stable -y\n\n# Add base common files used by all scenarios\nCOPY ./base/ /app/\n\n# Add bm package for scenario framework\nCOPY ./bm/ /app/bm/\n\n# Add scenario code, overriding anything from base\nCOPY ./${SCENARIO}/ /app/\n\nENV SCENARIO=${SCENARIO}\nENV PROFILE_BENCHMARKS=0\n\nENTRYPOINT [\"/app/entrypoint\"]\nCMD [\"/app/benchmark\"]\n",
            ".gitlab-ci.yml": "stages:\n  - package\n  - tests\n  - shared-pipeline\n  - benchmarks\n  - release\n\nvariables:\n  REPO_LANG: python # \"python\" is used everywhere rather than \"py\"\n  REPO_NOTIFICATION_CHANNEL: \"#apm-python-release\"\n  # CI_DEBUG_SERVICES: \"true\"\n\ndefault:\n  interruptible: true\n\ninclude:\n  - remote: https://gitlab-templates.ddbuild.io/libdatadog/include/one-pipeline.yml\n  - local: \".gitlab/services.yml\" # Include early so others can use the definitions\n  - local: \".gitlab/package.yml\"\n  - local: \".gitlab/release.yml\"\n  - local: \".gitlab/testrunner.yml\"\n  - local: \".gitlab/benchmarks/serverless.yml\"\n\ntests-gen:\n  stage: tests\n  extends: .testrunner\n  script:\n    - pip install riot==0.20.1\n    - export DD_NATIVE_SOURCES_HASH=$(scripts/get-native-sources-hash.sh)\n    - riot -v run --pass-env -s gitlab-gen-config -v\n  needs: []\n  artifacts:\n    paths:\n      - .gitlab/tests-gen.yml\n\nrun-tests-trigger:\n stage: tests\n needs: [ tests-gen ]\n trigger:\n   include:\n     - artifact: .gitlab/tests-gen.yml\n       job: tests-gen\n   strategy: depend\n\nmicrobenchmarks:\n  stage: benchmarks\n  needs: [ \"download_ddtrace_artifacts\" ]\n  trigger:\n    include: .gitlab/benchmarks/microbenchmarks.yml\n    strategy: depend\n  variables:\n    PARENT_PIPELINE_ID: $CI_PIPELINE_ID\n\nmacrobenchmarks:\n  stage: benchmarks\n  needs: [ ]\n  trigger:\n    include: .gitlab/benchmarks/macrobenchmarks.yml\n  allow_failure: true\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\"\n      when: always\n    - when: manual\n\ncheck_new_flaky_tests:\n  stage: tests\n  needs: [\"run-tests-trigger\"]\n  extends: .testrunner\n  script:\n    - export DD_SITE=datadoghq.com\n    - export DD_API_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.${CI_PROJECT_NAME}.dd-api-key-qualitygate --with-decryption --query \"Parameter.Value\" --out text)\n    - export DD_APP_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.${CI_PROJECT_NAME}.dd-app-key-qualitygate --with-decryption --query \"Parameter.Value\" --out text)\n    - datadog-ci gate evaluate\n  except:\n    - main\n    - '[0-9].[0-9]*'\n    - 'mq-working-branch**'\n\nrequirements_json_test:\n  rules:\n    - when: on_success\n  variables:\n    REQUIREMENTS_BLOCK_JSON_PATH: \".gitlab/requirements_block.json\"\n    REQUIREMENTS_ALLOW_JSON_PATH: \".gitlab/requirements_allow.json\"\n\npackage-oci:\n  needs: [ download_dependency_wheels, download_ddtrace_artifacts ]\n\npromote-oci-to-prod:\n  stage: release\n  rules: null\n  only:\n    # TODO: Support publishing rc releases\n    - /^v[0-9]+\\.[0-9]+\\.[0-9]+$/\n  needs:\n    - job: release_pypi_prod\n    - job: package-oci\n      artifacts: true\n    - job: oci-internal-publish\n      artifacts: true\n\npromote-oci-to-prod-beta:\n  stage: release\n  needs:\n    - job: package-oci\n      artifacts: true\n    - job: oci-internal-publish\n      artifacts: true\n\npromote-oci-to-staging:\n  stage: release\n  needs:\n    - job: package-oci\n      artifacts: true\n    - job: oci-internal-publish\n      artifacts: true\n\npublish-lib-init-ghcr-tags:\n  stage: release\n  rules: null\n  only:\n    # TODO: Support publishing rc releases\n    - /^v[0-9]+\\.[0-9]+\\.[0-9]+$/\n  needs:\n    - job: release_pypi_prod\n    - job: create-multiarch-lib-injection-image\n\npublish-lib-init-pinned-tags:\n  stage: release\n  rules: null\n  only:\n    # TODO: Support publishing rc releases\n    - /^v[0-9]+\\.[0-9]+\\.[0-9]+$/\n  needs:\n    - job: release_pypi_prod\n    - job: create-multiarch-lib-injection-image\n    - job: generate-lib-init-pinned-tag-values\n      artifacts: true\n\nonboarding_tests_installer:\n  parallel:\n    matrix:\n      - ONBOARDING_FILTER_WEBLOG: [test-app-python,test-app-python-container,test-app-python-alpine]\n        SCENARIO: [ SIMPLE_INSTALLER_AUTO_INJECTION, SIMPLE_AUTO_INJECTION_PROFILING ]\n\nonboarding_tests_k8s_injection:\n  parallel:\n    matrix:\n      - WEBLOG_VARIANT: [dd-lib-python-init-test-django, ]\n        SCENARIO: [K8S_LIB_INJECTION, K8S_LIB_INJECTION_UDS, K8S_LIB_INJECTION_NO_AC, K8S_LIB_INJECTION_NO_AC_UDS, K8S_LIB_INJECTION_PROFILING_DISABLED, K8S_LIB_INJECTION_PROFILING_ENABLED, K8S_LIB_INJECTION_PROFILING_OVERRIDE]\n        K8S_CLUSTER_VERSION: ['7.56.2', '7.59.0']\n\n      - WEBLOG_VARIANT: [dd-lib-python-init-test-django-gunicorn, dd-lib-python-init-test-django-gunicorn-alpine, dd-lib-python-init-test-django-unsupported-package-force, dd-lib-python-init-test-django-uvicorn, dd-lib-python-init-test-protobuf-old ]\n        SCENARIO: [K8S_LIB_INJECTION, K8S_LIB_INJECTION_PROFILING_ENABLED]\n        K8S_CLUSTER_VERSION: ['7.56.2', '7.59.0']\n\n      - WEBLOG_VARIANT: [dd-lib-python-init-test-django-preinstalled]\n        SCENARIO: [K8S_LIB_INJECTION, K8S_LIB_INJECTION_UDS, K8S_LIB_INJECTION_NO_AC, K8S_LIB_INJECTION_NO_AC_UDS]\n        K8S_CLUSTER_VERSION: ['7.56.2', '7.59.0']\n\ndeploy_to_reliability_env:\n  needs: []\n\ndeploy_to_di_backend:manual:\n  stage: shared-pipeline\n  rules:\n    - when: manual\n      allow_failure: true\n  trigger:\n    project: DataDog/debugger-demos\n    branch: main\n  variables:\n    UPSTREAM_PROJECT_ID: $CI_PROJECT_ID\n    UPSTREAM_PROJECT_NAME: $CI_PROJECT_NAME\n    UPSTREAM_COMMIT_SHORT_SHA: $CI_COMMIT_SHORT_SHA\n    UPSTREAM_PIPELINE_ID: $CI_PIPELINE_ID\n    UPSTREAM_COMMIT_AUTHOR: $CI_COMMIT_AUTHOR\n    UPSTREAM_TAG: $CI_COMMIT_TAG\n    UPSTREAM_PACKAGE_JOB: build\n",
            ".circleci/config.yml": "version: 2.1\n\npython310_image: &python310_image cimg/python:3.10.12\n\nsetup: true\n\nparameters:\n  coverage:\n    type: boolean\n    default: false\n  riot_run_latest:\n    type: boolean\n    default: false\n\n\norbs:\n  continuation: circleci/continuation@0.1.2\n\nexecutors:\n  python310:\n    docker:\n      - image: *python310_image\n    resource_class: small\n\njobs:\n  setup:\n    executor: python310\n    steps:\n      - checkout\n      - run:\n          name: Generate config\n          command: |\n            export GIT_COMMIT_DESC=$(git log -n 1 $CIRCLE_SHA1)\n            pip3 install riot==0.20.1\n            riot -P -v run --pass-env -s circleci-gen-config -- -v\n      - continuation/continue:\n          configuration_path: .circleci/config.gen.yml\n\nworkflows:\n  setup:\n    jobs:\n      - setup\n"
        },
        "static_files": {}
    },
    "project_structure": {
        "files": [
            "Dockerfile",
            "README.rst",
            "__init__.py"
        ],
        "folders": [
            "appsec_iast_aspects",
            "appsec_iast_propagation",
            "base",
            "bm",
            "core_api",
            "ddtrace_run",
            "django_simple",
            "encoder",
            "flask_simple",
            "flask_sqli",
            "http_propagation_extract",
            "http_propagation_inject",
            "iast_ast_patching",
            "otel_span",
            "packages_update_imported_dependencies",
            "rate_limiter",
            "sampling_rule_matches",
            "set_http_meta",
            "span",
            "startup",
            "telemetry_add_metric",
            "threading",
            "tracer"
        ]
    }
}