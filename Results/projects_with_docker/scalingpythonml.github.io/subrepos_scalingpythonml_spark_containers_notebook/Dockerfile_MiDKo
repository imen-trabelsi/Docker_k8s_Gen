FROM holdenk/jupyter-hub-magicsingleuser-sample:0.10.2-n412.h25a21283

LABEL maintainer="Your Name <your.email@example.com>"

ENV MAKEFLAGS -j 4
ENV LANG C.UTF-8
ENV JAVA_HOME /usr/local/openjdk-11
ENV PATH $JAVA_HOME/bin:$PATH
ENV SPARK_HOME /opt/spark

COPY jars /opt/spark/jars
COPY bin /opt/spark/bin
COPY sbin /opt/spark/sbin
COPY kubernetes/dockerfiles/spark/entrypoint.sh /opt/
COPY kubernetes/dockerfiles/spark/decom.sh* /opt/
COPY examples /opt/spark/examples
COPY kubernetes/tests /opt/spark/tests
COPY data /opt/spark/data
COPY LICENSE /opt/spark/LICENSE
COPY licenses /opt/spark/licenses
COPY python ${SPARK_HOME}/python

ADD https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.563/aws-java-sdk-bundle-1.11.563.jar ${SPARK_HOME}/jars/
ADD https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.2.0/hadoop-aws-3.2.0.jar ${SPARK_HOME}/jars/
ADD https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark3-runtime/0.11.0/iceberg-spark3-runtime-0.11.0.jar ${SPARK_HOME}/jars/
ADD https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark3-extensions/0.11.0/iceberg-spark3-extensions-0.11.0.jar ${SPARK_HOME}/jars/
ADD https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark3/0.11.0/iceberg-spark3-0.11.0.jar ${SPARK_HOME}/jars/

USER ${NB_USER}

EXPOSE 2222
EXPOSE 7777

RUN set -eux; \
apt-get update; apt-get install -yq graphviz git build-essential cmake telnet; \
ln -s /lib /lib64; \
apt install -y bash tini libc6 libpam-modules krb5-user libnss3 procps ca-certificates p11-kit wget bzip2 git mercurial subversion; \
mkdir -p /opt/spark; \
mkdir -p /opt/spark/examples; \
mkdir -p /opt/spark/work-dir; \
touch /opt/spark/RELEASE; \
rm /bin/sh; ln -sv /bin/bash /bin/sh; \
echo "auth required pam_wheel.so use_uid" >> /etc/pam.d/su; \
chgrp root /etc/passwd && chmod ug+rw /etc/passwd; \
conda install -c conda-forge --yes mamba; \
mamba install --yes python==3.8.6; \
pip install --upgrade pip setuptools; \
mamba install --yes numpy==1.19.2 pandas cytoolz numba lz4 scikit-build python-blosc=1.9.2; \
(mamba install --yes pyarrow ||  pip install -vvv pyarrow); \
apt-get clean; rm -rf /var/cache/apt/*; rm -rf /var/lib/apt/lists/*; \
echo -e "$NB_USER\n$NB_USER" | passwd $NB_USER; \
{ echo '#/bin/sh'; echo 'echo "$JAVA_HOME"'; } > /usr/local/bin/docker-java-home; \
chmod +x /usr/local/bin/docker-java-home; \
[ "$JAVA_HOME" = "$(docker-java-home)" ]; \
ENV JAVA_VERSION 11.0.9.1; \
chmod g+w /opt/spark/work-dir; \
chmod a+x /opt/decom.sh*; \
pip install -e ${SPARK_HOME}/python; \

CMD [ "/opt/spark/bin/spark-submit", "--class", "com.example.YourClass", "--master", "local[*]", "/path/to/your.jar" ]
